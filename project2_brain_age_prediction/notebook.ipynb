{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25aa3366-398d-41e7-bf28-8e2cd3fa886f",
   "metadata": {},
   "source": [
    "## AML Project 1 \n",
    "### Brain Age Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c88a34-6b16-4e43-b423-e8b7eb19a74c",
   "metadata": {},
   "source": [
    "#### Objective\n",
    "The objective of this project is to predict the age of the brain based on MRI-derived features. The dataset contains multiple features extracted from MRI scans, which serve as input variables for predicting brain age, a continuous target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb5ac4c-c9ce-441e-832d-0e0326e7d5ab",
   "metadata": {},
   "source": [
    "#### Goal\n",
    "The goal is to develop a regression model capable of predicting brain age with an ùëÖ2 score of at least 0.5, meeting the baseline requirements for this task. \n",
    "\n",
    "Therefore, the predictions will be evaluated using the Coefficient of Determination (ùëÖ2) on a reserved test dataset.\n",
    "\n",
    "The data preprocessing involves the following steps:\n",
    "\n",
    "- Outlier Detection\n",
    "- Feature Selection\n",
    "- Imputation of Missing Values\n",
    "\n",
    "Finally, submit a prediction file that includes two columns: id and y (predicted brain age).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0944568-92c0-4b52-af3c-c43aee148d46",
   "metadata": {},
   "source": [
    "#### Dataset Overview\n",
    "\n",
    "The dataset includes:\n",
    "\n",
    "- Training Data (X_train.csv): Contains 831 numerical MRI features for 1212 samples. These features serve as input variables for training the model. Each sample is linked to a corresponding target brain age in the y_train.csv file.\n",
    "\n",
    "- Test Data (X_test.csv): Contains 831 numerical MRI features for 776 samples. These features are used for generating predictions during the testing phase. The test dataset does not include target labels.\n",
    "\n",
    "- Labels (y_train.csv): Contains the target brain ages (in years) for the training samples.\n",
    "\n",
    "- Sample Submission (sample.csv): Provides a template for submitting predictions. It includes the id column and a placeholder for predicted ages (y). Predictions for the test set must follow this format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb432329-80fc-4f73-a636-494409a932f7",
   "metadata": {},
   "source": [
    "#### Approach\n",
    "\n",
    "The project is divided into the following steps:\n",
    "\n",
    "###### Data Observation and Preprocessing:\n",
    "- Handle missing values.\n",
    "- Detect and address outliers.\n",
    "- Perform feature selection to reduce dimensionality and retain relevant features.\n",
    "\n",
    "###### Model Development:\n",
    "- Train regression models to predict brain age.\n",
    "- Tune hyperparameters to optimize performance.\n",
    "\n",
    "###### Evaluation:\n",
    "- Validate the model using ùëÖ2 on the validation set.\n",
    "\n",
    "Submit predictions for the test set in the required format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfef2e7d-737d-416c-a6a3-3f2b23497c3d",
   "metadata": {},
   "source": [
    "### 1. Data Observation and Preprocessing\n",
    "\n",
    "#### 1.1 Summary Statistics and Data Owerview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "736ea6c7-c009-409b-a65b-5e4a5ebeccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee52b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df_train = pd.read_csv('X_train.csv')\n",
    "df_labels = pd.read_csv('y_train.csv')\n",
    "df_test = pd.read_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "920670ae-5de2-4eba-a157-a20ec8b96857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14168.823171</td>\n",
       "      <td>10514.380717</td>\n",
       "      <td>3316.149698</td>\n",
       "      <td>94230.695124</td>\n",
       "      <td>102.386606</td>\n",
       "      <td>92.677127</td>\n",
       "      <td>11108.748199</td>\n",
       "      <td>10866.505510</td>\n",
       "      <td>10837.622093</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12352.094085</td>\n",
       "      <td>846.014651</td>\n",
       "      <td>105.132144</td>\n",
       "      <td>102.112809</td>\n",
       "      <td>2090.004260</td>\n",
       "      <td>2.691845</td>\n",
       "      <td>1234.374109</td>\n",
       "      <td>1000.784475</td>\n",
       "      <td>9285.751272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17757.037554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4101.016273</td>\n",
       "      <td>92959.527633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.855168</td>\n",
       "      <td>10013.959449</td>\n",
       "      <td>10826.607494</td>\n",
       "      <td>10076.101597</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16198.071494</td>\n",
       "      <td>776.084467</td>\n",
       "      <td>106.385590</td>\n",
       "      <td>103.472030</td>\n",
       "      <td>2474.051881</td>\n",
       "      <td>2.287976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012.626705</td>\n",
       "      <td>11750.284764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>14226.656663</td>\n",
       "      <td>11029.642499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124055.600561</td>\n",
       "      <td>100.542483</td>\n",
       "      <td>92.860892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10492.342868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10329.704431</td>\n",
       "      <td>13976.063780</td>\n",
       "      <td>737.040332</td>\n",
       "      <td>103.671234</td>\n",
       "      <td>109.458246</td>\n",
       "      <td>2656.083281</td>\n",
       "      <td>2.843706</td>\n",
       "      <td>888.353607</td>\n",
       "      <td>1048.810385</td>\n",
       "      <td>9553.922728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 833 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id            x0            x1           x2             x3          x4  \\\n",
       "0  0.0  14168.823171  10514.380717  3316.149698   94230.695124  102.386606   \n",
       "1  1.0  17757.037554           NaN  4101.016273   92959.527633         NaN   \n",
       "2  2.0  14226.656663  11029.642499          NaN  124055.600561  100.542483   \n",
       "\n",
       "          x5            x6            x7            x8  ...          x822  \\\n",
       "0  92.677127  11108.748199  10866.505510  10837.622093  ...           NaN   \n",
       "1  99.855168  10013.959449  10826.607494  10076.101597  ...           NaN   \n",
       "2  92.860892           NaN  10492.342868           NaN  ...  10329.704431   \n",
       "\n",
       "           x823        x824        x825        x826         x827      x828  \\\n",
       "0  12352.094085  846.014651  105.132144  102.112809  2090.004260  2.691845   \n",
       "1  16198.071494  776.084467  106.385590  103.472030  2474.051881  2.287976   \n",
       "2  13976.063780  737.040332  103.671234  109.458246  2656.083281  2.843706   \n",
       "\n",
       "          x829         x830          x831  \n",
       "0  1234.374109  1000.784475   9285.751272  \n",
       "1          NaN  1012.626705  11750.284764  \n",
       "2   888.353607  1048.810385   9553.922728  \n",
       "\n",
       "[3 rows x 833 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aff632c-554b-49f8-94e6-47a3e55da3a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for X_train:\n",
      "                id            x0            x1           x2             x3  \\\n",
      "count  1212.000000   1121.000000   1128.000000  1124.000000    1121.000000   \n",
      "mean    605.500000  15220.402957  10950.160761  3430.837498  100002.281022   \n",
      "std     350.018571   2314.735855   1570.611458   443.431441    9708.061111   \n",
      "min       0.000000   5636.623777   6764.060541  1849.453269   65828.916291   \n",
      "25%     302.750000  13846.177869   9859.438276  3152.193184   93497.927859   \n",
      "50%     605.500000  15048.467618  10839.483074  3401.539562  100053.800306   \n",
      "75%     908.250000  16653.018233  11902.078799  3698.564818  106139.852699   \n",
      "max    1211.000000  28273.690135  17777.338221  5622.951648  133145.632257   \n",
      "\n",
      "                x4           x5            x6            x7            x8  \\\n",
      "count  1138.000000  1133.000000   1115.000000   1113.000000   1129.000000   \n",
      "mean    105.070358    99.968855   9983.055476  10496.207179  10495.835570   \n",
      "std       2.834582     9.566001    981.199159    278.859974    288.802549   \n",
      "min     100.056578    70.232469   6797.836298  10000.771287  10000.339782   \n",
      "25%     102.679233    93.586112   9351.114468  10260.607893  10242.516364   \n",
      "50%     105.029940    99.670635   9991.006638  10498.862876  10494.225267   \n",
      "75%     107.516555   106.045433  10588.909713  10732.429943  10734.838005   \n",
      "max     110.087261   130.142499  13865.848591  11000.062311  10999.403374   \n",
      "\n",
      "       ...          x822          x823         x824         x825         x826  \\\n",
      "count  ...   1122.000000   1128.000000  1117.000000  1116.000000  1102.000000   \n",
      "mean   ...  10069.191241  13274.793928   812.316152   104.968652   105.063790   \n",
      "std    ...    964.684756   2160.273617   180.550450     2.805768     2.819128   \n",
      "min    ...   7109.997185   4100.700865   164.997735   100.040624   100.015930   \n",
      "25%    ...   9416.786301  11977.061474   694.099781   102.584331   102.615677   \n",
      "50%    ...  10064.750764  13160.555394   792.045039   104.969600   105.136788   \n",
      "75%    ...  10696.714321  14512.572842   925.032457   107.309535   107.407093   \n",
      "max    ...  13173.145338  24901.251674  1589.225040   110.072565   110.069056   \n",
      "\n",
      "              x827         x828         x829         x830          x831  \n",
      "count  1111.000000  1117.000000  1120.000000  1132.000000   1116.000000  \n",
      "mean   2482.685073     2.725659  1359.981226  1052.256384   9981.085085  \n",
      "std     523.215963     0.263641   265.345180    29.172210   1014.488328  \n",
      "min     750.038434     1.590647   663.173673  1000.067137   6383.771227  \n",
      "25%    2155.245200     2.537801  1177.188917  1028.203921   9316.722099  \n",
      "50%    2459.092168     2.710103  1362.350726  1053.778881   9981.210986  \n",
      "75%    2791.051349     2.887536  1535.159914  1077.716726  10647.455420  \n",
      "max    4904.988601     3.795277  2506.104650  1099.975679  13265.026039  \n",
      "\n",
      "[8 rows x 833 columns]\n"
     ]
    }
   ],
   "source": [
    "# train dataset\n",
    "print(\"Summary Statistics for X_train:\")\n",
    "print(df_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8769dc7-d597-4067-b84c-0497ee970239",
   "metadata": {},
   "source": [
    "##### Observations for Training Features (X_train)\n",
    "Counts: Many features (e.g., x1, x2, x3 ..) have fewer counts than the total rows (1212). This indicates missing values in those columns.\n",
    "\n",
    "Mean and Standard Deviation: Features like x0, x3, and others exhibit large standard deviations relative to their mean values, suggesting a wide spread or high variability in the data.\n",
    "\n",
    "Min and Max: Certain features (e.g., x0, x3) have significantly large ranges between their minimum and maximum values. This could indicate outliers or very different scales across features.\n",
    "\n",
    "Feature Distributions: Quartile values (25%, 50%, 75%) show some features (e.g., x5, x6) have distributions that are fairly compact, while others (e.g., x0, x3) have broader spreads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "698584f7-9328-4c66-a4f5-b1d7276e8839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>...</th>\n",
       "      <th>x822</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14655.540585</td>\n",
       "      <td>9917.388635</td>\n",
       "      <td>3368.691863</td>\n",
       "      <td>104367.124458</td>\n",
       "      <td>104.132894</td>\n",
       "      <td>95.412138</td>\n",
       "      <td>9222.286185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10054.751221</td>\n",
       "      <td>...</td>\n",
       "      <td>9153.072463</td>\n",
       "      <td>12039.009308</td>\n",
       "      <td>714.005017</td>\n",
       "      <td>105.651509</td>\n",
       "      <td>103.574436</td>\n",
       "      <td>2628.082823</td>\n",
       "      <td>2.766271</td>\n",
       "      <td>1553.285942</td>\n",
       "      <td>1037.998392</td>\n",
       "      <td>9762.400011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13875.822363</td>\n",
       "      <td>9955.163751</td>\n",
       "      <td>3118.195658</td>\n",
       "      <td>103577.269601</td>\n",
       "      <td>103.290975</td>\n",
       "      <td>86.916779</td>\n",
       "      <td>9625.725002</td>\n",
       "      <td>10592.011548</td>\n",
       "      <td>10234.818476</td>\n",
       "      <td>...</td>\n",
       "      <td>9915.292110</td>\n",
       "      <td>12579.041315</td>\n",
       "      <td>695.070183</td>\n",
       "      <td>106.900274</td>\n",
       "      <td>105.241730</td>\n",
       "      <td>2388.096545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1386.519117</td>\n",
       "      <td>1088.519466</td>\n",
       "      <td>11748.788738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>14807.162495</td>\n",
       "      <td>10682.476988</td>\n",
       "      <td>3335.687716</td>\n",
       "      <td>106647.642610</td>\n",
       "      <td>109.481676</td>\n",
       "      <td>86.476353</td>\n",
       "      <td>9128.693785</td>\n",
       "      <td>10880.979240</td>\n",
       "      <td>10485.268796</td>\n",
       "      <td>...</td>\n",
       "      <td>9733.845509</td>\n",
       "      <td>11009.075093</td>\n",
       "      <td>663.093857</td>\n",
       "      <td>105.541065</td>\n",
       "      <td>101.875603</td>\n",
       "      <td>2097.004365</td>\n",
       "      <td>2.362592</td>\n",
       "      <td>1204.527342</td>\n",
       "      <td>1067.697534</td>\n",
       "      <td>12487.217965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>12253.667985</td>\n",
       "      <td>9001.609788</td>\n",
       "      <td>2631.482012</td>\n",
       "      <td>91105.570966</td>\n",
       "      <td>108.741037</td>\n",
       "      <td>84.542046</td>\n",
       "      <td>9765.458299</td>\n",
       "      <td>10953.438053</td>\n",
       "      <td>10190.986014</td>\n",
       "      <td>...</td>\n",
       "      <td>11204.016625</td>\n",
       "      <td>9395.016940</td>\n",
       "      <td>656.018142</td>\n",
       "      <td>104.816602</td>\n",
       "      <td>107.213434</td>\n",
       "      <td>2035.045976</td>\n",
       "      <td>3.052844</td>\n",
       "      <td>794.341243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7931.828963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>18925.988003</td>\n",
       "      <td>12161.366373</td>\n",
       "      <td>3724.006508</td>\n",
       "      <td>110262.565336</td>\n",
       "      <td>102.085795</td>\n",
       "      <td>107.920270</td>\n",
       "      <td>9494.243179</td>\n",
       "      <td>10684.550944</td>\n",
       "      <td>10074.187696</td>\n",
       "      <td>...</td>\n",
       "      <td>11093.701929</td>\n",
       "      <td>13876.039832</td>\n",
       "      <td>964.037692</td>\n",
       "      <td>104.557952</td>\n",
       "      <td>109.185247</td>\n",
       "      <td>2971.082813</td>\n",
       "      <td>2.571392</td>\n",
       "      <td>1207.265749</td>\n",
       "      <td>1013.661254</td>\n",
       "      <td>8241.962297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 833 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id            x0            x1           x2             x3          x4  \\\n",
       "0  0.0  14655.540585   9917.388635  3368.691863  104367.124458  104.132894   \n",
       "1  1.0  13875.822363   9955.163751  3118.195658  103577.269601  103.290975   \n",
       "2  2.0  14807.162495  10682.476988  3335.687716  106647.642610  109.481676   \n",
       "3  3.0  12253.667985   9001.609788  2631.482012   91105.570966  108.741037   \n",
       "4  4.0  18925.988003  12161.366373  3724.006508  110262.565336  102.085795   \n",
       "\n",
       "           x5           x6            x7            x8  ...          x822  \\\n",
       "0   95.412138  9222.286185           NaN  10054.751221  ...   9153.072463   \n",
       "1   86.916779  9625.725002  10592.011548  10234.818476  ...   9915.292110   \n",
       "2   86.476353  9128.693785  10880.979240  10485.268796  ...   9733.845509   \n",
       "3   84.542046  9765.458299  10953.438053  10190.986014  ...  11204.016625   \n",
       "4  107.920270  9494.243179  10684.550944  10074.187696  ...  11093.701929   \n",
       "\n",
       "           x823        x824        x825        x826         x827      x828  \\\n",
       "0  12039.009308  714.005017  105.651509  103.574436  2628.082823  2.766271   \n",
       "1  12579.041315  695.070183  106.900274  105.241730  2388.096545       NaN   \n",
       "2  11009.075093  663.093857  105.541065  101.875603  2097.004365  2.362592   \n",
       "3   9395.016940  656.018142  104.816602  107.213434  2035.045976  3.052844   \n",
       "4  13876.039832  964.037692  104.557952  109.185247  2971.082813  2.571392   \n",
       "\n",
       "          x829         x830          x831  \n",
       "0  1553.285942  1037.998392   9762.400011  \n",
       "1  1386.519117  1088.519466  11748.788738  \n",
       "2  1204.527342  1067.697534  12487.217965  \n",
       "3   794.341243          NaN   7931.828963  \n",
       "4  1207.265749  1013.661254   8241.962297  \n",
       "\n",
       "[5 rows x 833 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "868adbd3-d7f3-4aa3-9f0e-489ae1a9cf34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics X_test:\n",
      "               id            x0            x1           x2             x3  \\\n",
      "count  776.000000    725.000000    722.000000   732.000000     733.000000   \n",
      "mean   387.500000  15344.410832  10906.681312  3442.022564  100538.424402   \n",
      "std    224.156196   2018.156097   1450.216427   407.464522   10317.233706   \n",
      "min      0.000000   7824.415331   6996.984058  2335.281266   70097.079236   \n",
      "25%    193.750000  13879.324474   9941.576512  3158.828463   93073.980377   \n",
      "50%    387.500000  15181.156582  10717.578244  3416.413527  101088.758342   \n",
      "75%    581.250000  16613.593078  11750.391470  3697.111946  107028.300658   \n",
      "max    775.000000  20995.447337  17677.685164  5060.697780  137224.276391   \n",
      "\n",
      "               x4          x5            x6            x7            x8  ...  \\\n",
      "count  733.000000  731.000000    738.000000    728.000000    730.000000  ...   \n",
      "mean   105.001292  100.762208  10013.606995  10506.974919  10484.754548  ...   \n",
      "std      2.916754    9.976019   1014.029180    295.498152    288.659426  ...   \n",
      "min    100.080773   69.007982   6968.734040  10000.106804  10001.399332  ...   \n",
      "25%    102.371827   93.866256   9312.528029  10248.397638  10230.912551  ...   \n",
      "50%    105.092776  100.934281  10010.911944  10506.449856  10482.561274  ...   \n",
      "75%    107.488714  107.498035  10587.401128  10774.149622  10727.737434  ...   \n",
      "max    110.073897  132.629127  13927.198953  10998.559447  10999.626815  ...   \n",
      "\n",
      "               x822          x823         x824        x825        x826  \\\n",
      "count    729.000000    732.000000   735.000000  731.000000  706.000000   \n",
      "mean    9962.009541  13304.782128   814.853895  105.110363  104.896802   \n",
      "std     1037.955956   1837.206047   174.122958    2.886913    2.847184   \n",
      "min     6864.185163   7835.098011   413.090868  100.073534  100.029712   \n",
      "25%     9238.350275  12036.522139   689.019101  102.587063  102.448151   \n",
      "50%     9939.389494  13208.057914   794.068157  105.166398  104.746631   \n",
      "75%    10664.143609  14444.511448   918.556934  107.662498  107.369759   \n",
      "max    13417.496182  19358.061910  1563.030870  109.997691  110.063820   \n",
      "\n",
      "              x827        x828         x829         x830          x831  \n",
      "count   734.000000  724.000000   729.000000   742.000000    717.000000  \n",
      "mean   2495.551937    2.724719  1362.749284  1050.051403   9971.273535  \n",
      "std     473.819971    0.256718   275.273941    28.767775   1052.571645  \n",
      "min    1031.078259    1.995931   654.620939  1000.246111   6451.532823  \n",
      "25%    2154.548405    2.557656  1179.029464  1024.712389   9293.280244  \n",
      "50%    2459.064935    2.703757  1357.179972  1051.603776  10009.868114  \n",
      "75%    2822.012129    2.886560  1545.731609  1074.278372  10699.159851  \n",
      "max    4348.025399    3.796499  2258.399645  1100.028921  13359.745638  \n",
      "\n",
      "[8 rows x 833 columns]\n"
     ]
    }
   ],
   "source": [
    "# test dataset\n",
    "print(\"Summary Statistics X_test:\")\n",
    "print(df_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e69af56-484d-4e1b-86e9-edf30d1d7126",
   "metadata": {},
   "source": [
    "#### Observations for Test Features (X_test)\n",
    "Similar observations apply here, but with smaller counts due to the smaller size of the test set (776 rows).\n",
    "\n",
    "Missing values are present in features like x1, x2, x3, and others.\n",
    "\n",
    "Feature distributions are consistent with the training set, which is good for maintaining data similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a4cf51-092f-48cd-8a20-c9bf358a8307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     y\n",
       "0  0.0  74.0\n",
       "1  1.0  51.0\n",
       "2  2.0  70.0\n",
       "3  3.0  52.0\n",
       "4  4.0  85.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fee62c4-28f9-4fe4-835d-217f48ca2ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic Statistics for Labels (y_train):\n",
      "                id            y\n",
      "count  1212.000000  1212.000000\n",
      "mean    605.500000    69.889439\n",
      "std     350.018571     9.720843\n",
      "min       0.000000    42.000000\n",
      "25%     302.750000    64.000000\n",
      "50%     605.500000    70.000000\n",
      "75%     908.250000    77.000000\n",
      "max    1211.000000    97.000000\n"
     ]
    }
   ],
   "source": [
    "# Display basic statistics for the labels (y_train)\n",
    "print(\"\\nBasic Statistics for Labels (y_train):\")\n",
    "print(df_labels.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80afa803-076a-4670-85c7-b85bb09e6ce1",
   "metadata": {},
   "source": [
    "##### Observations for Labels (y_train):\n",
    "Analyzing the labels makes sense to understand the target distribution.\n",
    "- Count: All 1212 rows have labels, so no missing values are present in y_train.\n",
    "\n",
    "- Range: The ages range from 42 to 97 years, providing the regression target for the model. It has a mean of 69.89 and a standard deviation of 9.72.\n",
    "\n",
    "- Quartiles:\n",
    "\n",
    "25% of samples have ages ‚â§ 64;\n",
    "\n",
    "50% of samples have ages ‚â§ 70 (median);\n",
    "\n",
    "75% of samples have ages ‚â§ 77.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6da12-59bf-4423-a0fb-b1deeeb54920",
   "metadata": {},
   "source": [
    "#### 1.2 Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e080c70-ae55-46b5-b991-59706c78d926",
   "metadata": {},
   "source": [
    "Handling missing values is a critical step in the data preprocessing pipeline, as they can impact model performance and analysis accuracy.\n",
    "\n",
    "The percentage of missing values was calculated for both the training and testing datasets to understand the extent of missing data. This step helps identify patterns and discrepancies between the datasets.\n",
    "\n",
    "The missing value percentages for training and testing datasets were combined into a single table to allow for easy comparison and to observe the consistency of missing values across both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "801e9aa6-2bfc-466b-9666-6c16ae7b14ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage of Missing Values in Training and Testing Data:\n",
      "      Training Data (%)  Testing Data (%)\n",
      "id             0.000000          0.000000\n",
      "x0             7.508251          6.572165\n",
      "x1             6.930693          6.958763\n",
      "x2             7.260726          5.670103\n",
      "x3             7.508251          5.541237\n",
      "...                 ...               ...\n",
      "x827           8.333333          5.412371\n",
      "x828           7.838284          6.701031\n",
      "x829           7.590759          6.056701\n",
      "x830           6.600660          4.381443\n",
      "x831           7.920792          7.603093\n",
      "\n",
      "[833 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculation\n",
    "missing_train = df_train.isnull().mean() * 100\n",
    "missing_test = df_test.isnull().mean() * 100\n",
    "\n",
    "# Combining the results\n",
    "missing_values_comparison = pd.DataFrame({\n",
    "    'Training Data (%)': missing_train,\n",
    "    'Testing Data (%)': missing_test\n",
    "})\n",
    "\n",
    "print(\"\\nPercentage of Missing Values in Training and Testing Data:\")\n",
    "print(missing_values_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcf2df2-4665-4f60-b6df-2c3c7cb2578f",
   "metadata": {},
   "source": [
    "##### Observations for missing data:\n",
    "\n",
    "The training dataset contains missing values across many features, with percentages ranging from 0% to 8.33%.\n",
    "\n",
    "The testing dataset also contains missing values across many features, with percentages ranging from 0% to 7.60%.\n",
    "\n",
    "Missing values will need to be addressed to ensure the consistency and reliability of the dataset for further analysis and model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af4906-422f-41eb-822f-64064d38cc99",
   "metadata": {},
   "source": [
    "#### 1.3 Data Preparation\n",
    "##### Extracting and Removing Identifier Columns\n",
    "\n",
    "The first column of the testing dataset (df_test) contains unique identifiers for each sample, which are not used for model training but are necessary for creating the final submission, therefore this column should be extracted and stored in a new DataFrame (df_id).\n",
    "\n",
    "In general, identifier columns do not contribute to predictive modeling as they carry no meaningful feature information.\n",
    "Including them could lead to incorrect model assumptions or overfitting. Preserving df_id ensures that the predictions made by the model can be accurately matched back to their respective samples during submission.\n",
    " \n",
    "Also, for both the training and testing datasets, the ID column should be removed to focus solely on the feature and target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a52d08b2-7528-4c98-a04c-411d05656df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = df_test.iloc[:,0:1]\n",
    "\n",
    "# Remove first column\n",
    "df_X = df_train.iloc[:,1:]\n",
    "df_y = df_labels.iloc[:,1:]\n",
    "df_test = df_test.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30f72f-caba-4acc-bb2e-49a866caad63",
   "metadata": {},
   "source": [
    "The remaining data is split into the following:\n",
    "- df_X: The training features (excluding the first column).\n",
    "- df_y: The target labels extracted from a separate dataset (df_labels).\n",
    "- df_test: The testing features without the identifier column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc65a0b-480f-42e3-be4a-addecceea989",
   "metadata": {},
   "source": [
    "#### 1.4 Shuffling the Training Data\n",
    "\n",
    "Shuffling the training data adds randomness, which is crucial for creating a reliable and unbiased model. Without shuffling, the data might have an inherent order, such as being grouped by class labels or sorted by feature values. In such cases, the model could unintentionally learn these order-based patterns rather than focusing on the meaningful relationships between features and target labels. This can lead to overfitting or poor performance when the model encounters new, unseen data.\n",
    "\n",
    "To facilitate shuffling, the feature dataset (df_X) and the target labels (df_y) are concatenated into a single DataFrame (df_all). \n",
    "This step ensures that features and their corresponding target labels are aligned during the shuffling process.\n",
    "\n",
    "The combined dataset is shuffled randomly using the sample(frac=1) method. The parameter frac=1 means the entire dataset is shuffled. A fixed random_state is provided to ensure reproducibility, so every time this code runs, the shuffling produces the same result.\n",
    "\n",
    "\n",
    "After shuffling, the features and target labels are separated back into two datasets: df_X for the features and df_y for the target labels. This ensures the shuffled data is ready for use in the training process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff575cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle training data\n",
    "df_all = pd.concat([df_X, df_y], axis=1)\n",
    "shuffled_all = df_all.sample(frac=1, random_state=0)\n",
    "\n",
    "df_X = shuffled_all.iloc[:,:-1]\n",
    "df_y = shuffled_all.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f4ca2c-7f0d-434e-ae81-43f469befc2d",
   "metadata": {},
   "source": [
    "### 2.  Helper Functions\n",
    "##### 2.1 Feature Selection\n",
    "These functions help reduce dimensionality by removing features that are highly correlated or constant, which can degrade model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "693cf5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import DropCorrelatedFeatures, SmartCorrelatedSelection\n",
    "\n",
    "def remove_X_correlated_features(X_train, alpha=0.99):\n",
    "    \n",
    "    dcor_tr = DropCorrelatedFeatures(threshold=alpha)\n",
    "    X_train_decr = dcor_tr.fit(X_train)\n",
    "\n",
    "    mask = dcor_tr.get_support()\n",
    "    return np.array(mask)\n",
    "\n",
    "def fs_x_correlation(X_train, X_test, alpha=0.99):\n",
    "    \n",
    "    mask1 = remove_X_correlated_features(X_train, alpha=alpha)\n",
    "    \n",
    "    X_train_decor = X_train[:, mask1]\n",
    "    X_test_decor = X_test[:, mask1]\n",
    "    \n",
    "    return X_train_decor, X_test_decor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5f8a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import DropConstantFeatures\n",
    "\n",
    "def drop_constant_features(X_train, X_test):\n",
    "    \n",
    "    dconst_tr = DropConstantFeatures(missing_values='ignore')\n",
    "    X_train_dedup = dconst_tr.fit_transform(X_train)\n",
    "    X_test_dedup = dconst_tr.transform(X_test)\n",
    "    \n",
    "    return X_train_dedup, X_test_dedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06d97ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_nan_feature_selection(X_train, y_train, X_test, alpha_X=0.99, alpha_y=0.1):\n",
    "\n",
    "    X_train, X_test = fs_x_correlation(X_train, X_test, alpha=alpha_X)\n",
    "    X_train, X_test = drop_constant_features(X_train, X_test)\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9086d5-8a21-4620-a3e2-c780fdbf534e",
   "metadata": {},
   "source": [
    "#### 2.2 Missing Value Imputation\n",
    "\n",
    "Provides methods for imputing missing data using either KNN-based or median-based strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "652c924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "def impute_knn(X_train, X_test, n=20):\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=n)\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    \n",
    "    return X_train_imputed, X_test_imputed\n",
    "\n",
    "def impute_median(X_train, X_test):\n",
    "\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    \n",
    "    return X_train_imputed, X_test_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab05c3-9098-48ee-99f7-7dc85f49a648",
   "metadata": {},
   "source": [
    "#### 2.3 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdeff518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale(X_train, X_val):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    return X_train_scaled, X_val_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b804a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "def select_k_best(X_train, y_train, X_test, k, score_func):\n",
    "    \n",
    "    kbest = SelectKBest(k=k, score_func=score_func)\n",
    "    X_train_selected = kbest.fit_transform(X_train, y_train)\n",
    "    X_test_selected = kbest.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cebf76df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "def scale_and_impute(X_train, X_test):\n",
    "    \n",
    "    scale_and_impute_pipe = Pipeline([('scaler', StandardScaler()),('imputer', SimpleImputer(strategy='median'))])\n",
    "    X_train_imputed = scale_and_impute_pipe.fit_transform(X_train)\n",
    "    X_test_imputed = scale_and_impute_pipe.transform(X_test)\n",
    "    \n",
    "    return X_train_imputed, X_test_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440c50b-d576-4a62-8ee9-d8673caa3fe5",
   "metadata": {},
   "source": [
    "#### 2.4 Outlier Detection\n",
    "\n",
    "Outliers in the training set are detected and removed using the ECOD algorithm from the `pyod` library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d22d1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.ecod import ECOD\n",
    "\n",
    "def outlier_detection(X_train, y_train, contamination=0.01):\n",
    "\n",
    "    mask3 = ECOD_outlier_detection(X_train, y_train, contamination)\n",
    "    \n",
    "    mask = mask3.astype(int) == 1\n",
    "    \n",
    "    X_return = X_train[mask]\n",
    "    y_return = y_train[mask]\n",
    "    \n",
    "    print(X_train.shape, X_return.shape)\n",
    "    \n",
    "    return X_return, y_return\n",
    "    \n",
    "def ECOD_outlier_detection(X_train, y_train, contamination=0.01):\n",
    "    \n",
    "    estimator = ECOD(contamination=contamination)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    \n",
    "    distance = estimator.predict(X_train)\n",
    "    mask = distance != 1\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ba3c2-feda-4d13-8228-9b9cb530c033",
   "metadata": {},
   "source": [
    "### 3. Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b67e6-b220-4d4c-aaa4-4ea321da4aea",
   "metadata": {},
   "source": [
    "#### 3.1 Raw data preparation:\n",
    "Converts pandas DataFrames to NumPy arrays and prepares them for input into the ML pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aae40616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "X_train_raw = df_X.to_numpy()\n",
    "y_train_raw = df_y.to_numpy().ravel()\n",
    "X_test_raw = df_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2404c6dc-4223-422b-acfb-6a027dc2812a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1212, 827) (1212, 832)\n"
     ]
    }
   ],
   "source": [
    "# Feature selection before nan value imputation\n",
    "X_train_selected_nan, X_test_selected_nan = with_nan_feature_selection(X_train_raw, y_train_raw, X_test_raw, alpha_X=0.9999)\n",
    "print(X_train_selected_nan.shape, X_train_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d944639f-adfd-4db2-a518-263007519c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan value imputation\n",
    "X_train_selected, X_test_selected = impute_median(X_train_selected_nan, X_test_selected_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1bd9298-bde4-41f2-8093-d47508f575b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(X_train_selected).sum())  # Check for NaNs in the training set\n",
    "print(np.isnan(X_test_selected).sum())   # Check for NaNs in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ffebbe5-a0b8-4c55-94bb-52a4aaf3e9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "9.935455099994669e+23 -2.9379325892598552e+23\n"
     ]
    }
   ],
   "source": [
    "print(np.isinf(X_train_selected).sum())  # Check for infinities in training set\n",
    "print(np.isinf(X_test_selected).sum())   # Check for infinities in test set\n",
    "print(X_train_selected.max(), X_train_selected.min())  # Check data range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1b15da7-64a2-4d20-a9c8-6e6e64c8566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection after nan value imputation\n",
    "from scipy.stats import spearmanr, f, pearsonr\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression, chi2, f_classif\n",
    "\n",
    "def f_spearman(X, y):\n",
    "    corr_array = []\n",
    "    p_array = []\n",
    "    for i in range(X.shape[1]):\n",
    "        corr, p = spearmanr(X[:,i], y)\n",
    "        corr_array.append(abs(corr))\n",
    "        p_array.append(p)\n",
    "        \n",
    "    return corr_array, p_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "047269d6-3134-420c-a486-c9668ab9aeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:331: RuntimeWarning: invalid value encountered in sqrt\n",
      "  X_norms = np.sqrt(row_norms(X.T, squared=True) - n_samples * X_means**2)\n"
     ]
    }
   ],
   "source": [
    "X_train_kselected, X_test_kselected = select_k_best(X_train_selected, y_train_raw, X_test_selected, \n",
    "                                                    k=175, score_func=f_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c17b1a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/pyod/models/base.py:554: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1212, 175) (1199, 175)\n"
     ]
    }
   ],
   "source": [
    "# Outlier detection\n",
    "X_train_no_outliers, y_train_no_outliers = outlier_detection(X_train_kselected, y_train_raw, contamination=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b0faf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "X_train_scaled, X_test_scaled = scale(X_train_no_outliers, X_test_kselected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe276231",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_scaled\n",
    "X_test = X_test_scaled\n",
    "y_train = y_train_no_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec9b667-3fc7-4013-9c8e-460cdd103f61",
   "metadata": {},
   "source": [
    "### 4. Model Training and Evaluation\n",
    "\n",
    "In this section, we train multiple regression models to predict brain age based on extracted MRI features.\n",
    "We use cross-validation to evaluate model performance and compare different algorithms, including:\n",
    "\n",
    "- Linear Regression\n",
    "- Ridge Regression\n",
    "- Lasso Regression\n",
    "- ElasticNet\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092cc9fa-6410-4150-94e1-f00f255bce72",
   "metadata": {},
   "source": [
    "#### 4.1  Hyperparameter Tuning with GridSearchCV\n",
    "\n",
    "To optimize model performance, lets apply `GridSearchCV` to perform exhaustive search over specified hyperparameters.\n",
    "This helps us identify the best configuration for models like Ridge, Lasso, and ElasticNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b568ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def get_best_parameters(estimator, parameters):\n",
    "    \n",
    "    search = GridSearchCV(estimator=estimator, param_grid=parameters, scoring='r2', n_jobs=-1, cv=5, verbose=1)\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    print('Best params:', search.best_params_)\n",
    "    print('score:', search.best_score_)\n",
    "    print('best:', search.best_estimator_)\n",
    "    \n",
    "    return search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e879469-163a-4a2a-a664-02723048f47a",
   "metadata": {},
   "source": [
    "#### 4.2 Models \n",
    "This project explores several regression models to predict brain age using features derived from MRI scans. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b675dd-40db-4ea1-af35-d5fecfbff2e2",
   "metadata": {},
   "source": [
    "##### 4.2.1. Gaussian Process Regressor (GPR)\n",
    "This model uses a Gaussian Process with a RationalQuadratic kernel, which allows flexibility in modeling functions with varying smoothness. It performs Bayesian regression, capturing complex nonlinear patterns and providing uncertainty estimates for predictions. The hyperparameters ‚Äî including alpha and normalize_y ‚Äî were optimized via grid search.\n",
    "This model contributes valuable uncertainty-aware predictions to the final ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42e4cb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best params: {'alpha': 2.6366508987303554e-09, 'kernel': RationalQuadratic(alpha=0.6, length_scale=8), 'normalize_y': True}\n",
      "score: 0.6168104847972087\n",
      "best: GaussianProcessRegressor(alpha=2.6366508987303554e-09,\n",
      "                         kernel=RationalQuadratic(alpha=0.6, length_scale=8),\n",
      "                         normalize_y=True, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "\n",
    "rational_kernel = RationalQuadratic(alpha=0.6, length_scale=8)\n",
    "gpr = GaussianProcessRegressor(random_state=0)\n",
    "gpr_parameters = {'kernel' : [rational_kernel], 'alpha' : np.logspace(-10, -1, 20), 'normalize_y' : [True, False]}\n",
    "gpr_final = get_best_parameters(gpr, gpr_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddb68b1-ccaa-47b6-b81b-d3ac1323c4cf",
   "metadata": {},
   "source": [
    "##### 4.2.2 Cubist Regressor\n",
    "Cubist is a rule-based regression model that extends decision trees with linear models at the leaves. It builds a series of rule-based models (committees) and refines predictions using nearby neighbors for smoothing. In this implementation, the number of committees and neighbors were optimized using grid search.\n",
    "üß† This model adds interpretable, rule-based structure and strong performance to the ensemble.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0276406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best params: {'n_committees': 9, 'neighbors': 3}\n",
      "score: 0.569956198138764\n",
      "best: Cubist(n_committees=9, neighbors=3, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "from cubist import Cubist\n",
    "\n",
    "cub = Cubist(n_rules=500, random_state=0)\n",
    "cub_parameters = {'n_committees' : [1, 2, 3, 4, 5, 6, 7, 8, 9], 'neighbors' : [3, 4, 5, 6]}\n",
    "cub_final = get_best_parameters(cub, cub_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af47e59-c5c4-4747-8b80-be29cad1a431",
   "metadata": {},
   "source": [
    "##### 4.2.3 Support Vector Regressor (SVR)\n",
    "SVR is a powerful kernel-based regression model that aims to find a function within a specified margin of tolerance. In this case, we applied a custom Rational Quadratic kernel instead of the default RBF to better capture complex patterns in the data. The model was tuned over the C (regularization), epsilon (tube size), and kernel parameters using grid search.\n",
    "This model contributed non-linear flexibility and robustness to the ensemble.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d516726e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "Best params: {'C': 73.33333333333334, 'epsilon': 1e-05, 'kernel': RationalQuadratic(alpha=0.6, length_scale=8)}\n",
      "score: 0.6160210058988999\n",
      "best: SVR(C=73.33333333333334, epsilon=1e-05,\n",
      "    kernel=RationalQuadratic(alpha=0.6, length_scale=8))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "\n",
    "rational_kernel = RationalQuadratic(alpha=0.6, length_scale=8)\n",
    "svr = SVR()\n",
    "svr_parameters = {'kernel' : ['rbf', rational_kernel], 'epsilon' : np.logspace(-8, -1, 8), 'C' : np.linspace(50, 80, 10)}\n",
    "svr_final = get_best_parameters(svr, svr_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d9519e-9e3c-43e1-9dd8-92ed64da3e0a",
   "metadata": {},
   "source": [
    "##### 4.2.4 Gradient Boosting Regressor (GBR)\n",
    "Gradient Boosting is a powerful ensemble method that builds models sequentially to correct errors of previous models. In this implementation, hyperparameters such as n_estimators, learning_rate, min_samples_split, and max_depth were tuned via grid search. This model is particularly good at capturing non-linear patterns and reducing bias.\n",
    "GBR contributed stable and well-generalized predictions to the stacked ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea6b40aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best params: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "score: 0.5709102671576372\n",
      "best: GradientBoostingRegressor(n_estimators=1000, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "gbr_parameters = {'n_estimators' : [100, 500, 1000], 'learning_rate' : np.logspace(-3, -1, 3), 'min_samples_split' : [2, 3], 'max_depth' : [2, 3]}\n",
    "gbr_final = get_best_parameters(gbr, gbr_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa2a473-3451-41c6-935c-fdc7d14674d5",
   "metadata": {},
   "source": [
    "##### 4.2.5  Extra Trees Regressor (ETR)\n",
    "Extra Trees (Extremely Randomized Trees) is an ensemble learning method that builds multiple de-correlated decision trees using random splits of features and samples. It tends to reduce overfitting and improve generalization. In this implementation, n_estimators and min_samples_split were tuned.\n",
    "ETR introduced diversity and robustness to the stacked model, helping reduce variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fe52bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best params: {'min_samples_split': 2, 'n_estimators': 2000}\n",
      "score: 0.559179331472623\n",
      "best: ExtraTreesRegressor(n_estimators=2000, random_state=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "trees = ExtraTreesRegressor(random_state=0)\n",
    "trees_parameters = {'n_estimators' : [2000], 'min_samples_split' : [2, 3, 4, 5, 6]}\n",
    "trees_final = get_best_parameters(trees, trees_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff92d3-f8a0-4c22-ac3f-168f9802e64f",
   "metadata": {},
   "source": [
    "##### 4.2.6 CatBoost Regressor\n",
    "CatBoost is a high-performance gradient boosting algorithm developed by Yandex, optimized for categorical features and robust performance with minimal preprocessing. In this project, the model was tuned on the learning_rate parameter.\n",
    "üê± CatBoost contributed to the ensemble by leveraging its powerful regularization and efficient handling of non-linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "032cb42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best params: {'learning_rate': 0.07742636826811278}\n",
      "score: 0.5823264115578912\n",
      "best: <catboost.core.CatBoostRegressor object at 0x123c14a60>\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "cat = CatBoostRegressor(verbose=False)\n",
    "cat_parameters = {'learning_rate' : np.logspace(-5, 0, 10)}\n",
    "cat_final = get_best_parameters(cat, cat_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c24106-37a5-4183-bb2f-9a08e43d7fd5",
   "metadata": {},
   "source": [
    "### 5. Final Ensemble ‚Äì Stacking Regressor Architecture\n",
    "The final model is a stacking ensemble composed of the following base learners:\n",
    "\n",
    "- SVR (Support Vector Regressor): A kernel-based model that captures complex relationships, included to provide diversity in the ensemble.\n",
    "\n",
    "- Extra Trees Regressor: A randomized ensemble of decision trees, offering robustness and low bias; optimized with 2000 estimators.\n",
    "\n",
    "- CatBoost Regressor: A gradient boosting model efficient with categorical features; optimized for learning rate and showing strong performance in cross-validation.\n",
    "\n",
    "- Cubist: A rule-based regression model known for interpretability and strong generalization; contributes complementary predictive patterns.\n",
    "\n",
    "- Gradient Boosting Regressor (GBR): A well-tuned boosting model with 1000 estimators and learning rate optimization, contributing to the ensemble‚Äôs strength.\n",
    "\n",
    "All models were selected based on 5-fold cross-validation performance.\n",
    "The final estimator is a RidgeCV regressor, which learns to combine predictions from all base models in a regularized linear fashion.\n",
    "\n",
    "This stacked ensemble achieved the highest average cross-validation R¬≤ score (0.622) across all submissions and was selected for final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aaa0167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('svr', svr_final), ('trees', trees_final), ('cat', cat_final), ('cub', cub_final), ('gbr', gbr_final)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05cfa389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "K = 5\n",
    "cv_splitter = KFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d73ef5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svr: 5 fold CV score is 0.6160210058988999 and the list is \n",
      "[0.57974939 0.60918418 0.69969808 0.6577993  0.53367408]\n",
      "trees: 5 fold CV score is 0.559179331472623 and the list is \n",
      "[0.5106922  0.55687524 0.65288851 0.58768227 0.48775844]\n",
      "cat: 5 fold CV score is 0.5823264115578912 and the list is \n",
      "[0.51959126 0.58415126 0.66358088 0.6421751  0.50213356]\n",
      "cub: 5 fold CV score is 0.569956198138764 and the list is \n",
      "[0.53990847 0.56945203 0.64706684 0.62873484 0.4646188 ]\n",
      "gbr: 5 fold CV score is 0.5709102671576372 and the list is \n",
      "[0.46763857 0.58479549 0.64057714 0.62529389 0.53624625]\n"
     ]
    }
   ],
   "source": [
    "for name, regressor in estimators:\n",
    "    \n",
    "    score = cross_val_score(estimator=regressor, X=X_train, y=y_train, cv=cv_splitter, scoring='r2', n_jobs=-1)\n",
    "    mean_score = np.mean(score)\n",
    "\n",
    "    print(f\"{name}: {K} fold CV score is {mean_score} and the list is \\n{score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "181bd533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.560) total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.624) total time= 7.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.712) total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.674) total time=24.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.540) total time= 6.1min\n",
      "Stacking: 5 fold CV score is 0.6221823168274779 and the list is \n",
      "[0.56045363 0.62433992 0.71154566 0.67434739 0.54022498]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "stacking_regressor = StackingRegressor(estimators=estimators, n_jobs=-1)\n",
    "score = cross_val_score(estimator=stacking_regressor, X=X_train, y=y_train, cv=cv_splitter, scoring='r2', verbose=3)\n",
    "mean_score = np.mean(score)\n",
    "\n",
    "print(f\"Stacking: {K} fold CV score is {mean_score} and the list is \\n{score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dcf649cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(estimators=[(&#x27;svr&#x27;,\n",
       "                               SVR(C=73.33333333333334, epsilon=1e-05,\n",
       "                                   kernel=RationalQuadratic(alpha=0.6, length_scale=8))),\n",
       "                              (&#x27;trees&#x27;,\n",
       "                               ExtraTreesRegressor(n_estimators=2000,\n",
       "                                                   random_state=0)),\n",
       "                              (&#x27;cat&#x27;,\n",
       "                               &lt;catboost.core.CatBoostRegressor object at 0x123c14a60&gt;),\n",
       "                              (&#x27;cub&#x27;,\n",
       "                               Cubist(n_committees=9, neighbors=3,\n",
       "                                      random_state=0)),\n",
       "                              (&#x27;gbr&#x27;,\n",
       "                               GradientBoostingRegressor(n_estimators=1000,\n",
       "                                                         random_state=0))],\n",
       "                  n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;svr&#x27;,\n",
       "                               SVR(C=73.33333333333334, epsilon=1e-05,\n",
       "                                   kernel=RationalQuadratic(alpha=0.6, length_scale=8))),\n",
       "                              (&#x27;trees&#x27;,\n",
       "                               ExtraTreesRegressor(n_estimators=2000,\n",
       "                                                   random_state=0)),\n",
       "                              (&#x27;cat&#x27;,\n",
       "                               &lt;catboost.core.CatBoostRegressor object at 0x123c14a60&gt;),\n",
       "                              (&#x27;cub&#x27;,\n",
       "                               Cubist(n_committees=9, neighbors=3,\n",
       "                                      random_state=0)),\n",
       "                              (&#x27;gbr&#x27;,\n",
       "                               GradientBoostingRegressor(n_estimators=1000,\n",
       "                                                         random_state=0))],\n",
       "                  n_jobs=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(C=73.33333333333334, epsilon=1e-05,\n",
       "    kernel=RationalQuadratic(alpha=0.6, length_scale=8))</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>trees</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesRegressor</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesRegressor(n_estimators=2000, random_state=0)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cat</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostRegressor object at 0x123c14a60&gt;</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>cub</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Cubist</label><div class=\"sk-toggleable__content\"><pre>Cubist(n_committees=9, neighbors=3, random_state=0)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gbr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(n_estimators=1000, random_state=0)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeCV</label><div class=\"sk-toggleable__content\"><pre>RidgeCV()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(estimators=[('svr',\n",
       "                               SVR(C=73.33333333333334, epsilon=1e-05,\n",
       "                                   kernel=RationalQuadratic(alpha=0.6, length_scale=8))),\n",
       "                              ('trees',\n",
       "                               ExtraTreesRegressor(n_estimators=2000,\n",
       "                                                   random_state=0)),\n",
       "                              ('cat',\n",
       "                               <catboost.core.CatBoostRegressor object at 0x123c14a60>),\n",
       "                              ('cub',\n",
       "                               Cubist(n_committees=9, neighbors=3,\n",
       "                                      random_state=0)),\n",
       "                              ('gbr',\n",
       "                               GradientBoostingRegressor(n_estimators=1000,\n",
       "                                                         random_state=0))],\n",
       "                  n_jobs=-1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit to all training data\n",
    "stacking_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f156b0-7c60-44eb-89d5-d2738d92d536",
   "metadata": {},
   "source": [
    "### 6. Generating and Saving Predictions\n",
    "\n",
    "After selecting the best-performing model, predictions for the test dataset were generated.\n",
    "The predicted brain ages are saved in a CSV file formatted for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bae2e846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anyachenko/opt/miniconda3/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but Cubist was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id          y\n",
      "0      0.0  60.163707\n",
      "1      1.0  74.129793\n",
      "2      2.0  67.577205\n",
      "3      3.0  77.468771\n",
      "4      4.0  72.563396\n",
      "..     ...        ...\n",
      "771  771.0  65.840385\n",
      "772  772.0  73.255432\n",
      "773  773.0  77.025010\n",
      "774  774.0  72.764301\n",
      "775  775.0  62.834754\n",
      "\n",
      "[776 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create Submission\n",
    "y_predict = stacking_regressor.predict(X_test)\n",
    "submission = df_id.assign(y=y_predict)\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "edd75152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
